{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install opencv-contrib-python\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS_LOOKUP = {\n",
    "    (1, 1, 1, 1, 1, 1, 0): 0,\n",
    "    (1, 1, 0, 0, 0, 0, 0): 1,\n",
    "    (1, 0, 1, 1, 0, 1, 1): 2,\n",
    "    (1, 1, 1, 0, 0, 1, 1): 3,\n",
    "    (1, 1, 0, 0, 1, 0, 1): 4,\n",
    "    (0, 1, 1, 0, 1, 1, 1): 5,\n",
    "    (0, 1, 1, 1, 1, 1, 1): 6,\n",
    "    (1, 1, 0, 0, 0, 1, 0): 7,\n",
    "    (1, 1, 1, 1, 1, 1, 1): 8,\n",
    "    (1, 1, 1, 0, 1, 1, 1): 9,\n",
    "    (0, 0, 0, 0, 0, 1, 1): '-'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_W_Ratio = 1.9 # Height to Width Ratio\n",
    "THRESHOLD = 10 # Adaptive Threshold Binarization\n",
    "arc_tan_theta = 6.0  # Nixie tube tilt angle\n",
    "crop_y0 = 215 \n",
    "crop_y1 = 470\n",
    "crop_x0 = 260 \n",
    "crop_x1 = 890 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('image_path', help='path to image')\n",
    "# parser.add_argument('-s', '--show_image', action='store_const', const=True, help='whether to show image')\n",
    "# parser.add_argument('-d', '--is_debug', action='store_const', const=True, help='True or False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, show=False):\n",
    "    # todo: crop image and clear dc and ac signal\n",
    "    gray_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    blurred = cv2.GaussianBlur(gray_img, (7, 7), 0)\n",
    "    if show:\n",
    "        cv2.imshow('gray_img', gray_img)\n",
    "        cv2.imshow('blurred_img', blurred)\n",
    "    return blurred, gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, threshold, show=False, kernel_size=(5, 5)):\n",
    "    # Histogram local equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(6, 6))\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    # Adaptive Threshold Binarization\n",
    "    dst = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 127, threshold)\n",
    "    \n",
    "    # Close operation and open operation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, kernel_size)\n",
    "    dst = cv2.morphologyEx(dst, cv2.MORPH_CLOSE, kernel)\n",
    "    dst = cv2.morphologyEx(dst, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    if show:\n",
    "        cv2.imshow('equlizeHist', img)\n",
    "        cv2.imshow('threshold', dst)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_extract(one_d_array, threshold=20):\n",
    "    res = []\n",
    "    flag = 0\n",
    "    temp = 0\n",
    "    for i in range(len(one_d_array)):\n",
    "        if one_d_array[i] < 12 * 255:\n",
    "            if flag > threshold:\n",
    "                start = i - flag\n",
    "                end = i\n",
    "                temp = end\n",
    "                if end - start > 20:\n",
    "                    res.append((start, end))\n",
    "            flag = 0\n",
    "        else:\n",
    "            flag += 1\n",
    "\n",
    "    else:\n",
    "        if flag > threshold:\n",
    "            start = temp\n",
    "            end = len(one_d_array)\n",
    "            if end - start > 50:\n",
    "                res.append((start, end))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_digits_positions(img, reserved_threshold=20):\n",
    "    digits_positions = []\n",
    "    img_array = np.sum(img, axis=0)\n",
    "    horizon_position = helper_extract(img_array, threshold=reserved_threshold)\n",
    "    img_array = np.sum(img, axis=1)\n",
    "    vertical_position = helper_extract(img_array, threshold=reserved_threshold * 4)\n",
    "    # make vertical_position has only one element\n",
    "    if len(vertical_position) > 1:\n",
    "        vertical_position = [(vertical_position[0][0], vertical_position[len(vertical_position) - 1][1])]\n",
    "    for h in horizon_position:\n",
    "        for v in vertical_position:\n",
    "            digits_positions.append(list(zip(h, v)))\n",
    "    assert len(digits_positions) > 0, \"Failed to find digits's positions\"\n",
    "\n",
    "    return digits_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_digits_area_method(digits_positions, output_img, input_img):\n",
    "    digits = []\n",
    "    for c in digits_positions:\n",
    "        x0, y0 = c[0]\n",
    "        x1, y1 = c[1]\n",
    "        roi = input_img[y0:y1, x0:x1]\n",
    "        h, w = roi.shape\n",
    "        suppose_W = max(1, int(h / H_W_Ratio))\n",
    "        \n",
    "        # Separately identify the case of 1\n",
    "        if w < suppose_W / 2:\n",
    "            x0 = x0 + w - suppose_W\n",
    "            w = suppose_W\n",
    "            roi = input_img[y0:y1, x0:x1]\n",
    "        width = (max(int(w * 0.15), 1) + max(int(h * 0.15), 1)) // 2\n",
    "        dhc = int(width * 0.8)\n",
    "        # print('width :', width)\n",
    "        # print('dhc :', dhc)\n",
    "\n",
    "        small_delta = int(h / arc_tan_theta) // 4\n",
    "        # print('small_delta : ', small_delta)\n",
    "        \n",
    "        segments = [\n",
    "            ((w - width - small_delta, width // 2), (w, (h - dhc) // 2)),\n",
    "            ((w - width - 2 * small_delta, (h + dhc) // 2), (w - small_delta, h - width // 2)),\n",
    "            ((width - small_delta, h - width), (w - width - small_delta, h)),\n",
    "            ((0, (h + dhc) // 2), (width, h - width // 2)),\n",
    "            ((small_delta, width // 2), (small_delta + width, (h - dhc) // 2)),\n",
    "            ((small_delta, 0), (w + small_delta, width)),\n",
    "            ((width - small_delta, (h - dhc) // 2), (w - width - small_delta, (h + dhc) // 2))\n",
    "        ]\n",
    "        on = [0] * len(segments)\n",
    "\n",
    "        for (i, ((xa, ya), (xb, yb))) in enumerate(segments):\n",
    "            seg_roi = roi[ya:yb, xa:xb]\n",
    "            # plt.imshow(seg_roi)\n",
    "            # plt.show()\n",
    "            total = cv2.countNonZero(seg_roi)\n",
    "            area = (xb - xa) * (yb - ya) * 0.9\n",
    "            print(total / float(area))\n",
    "            if total / float(area) > 0.45:\n",
    "                on[i] = 1\n",
    "\n",
    "        # print(on)\n",
    "\n",
    "        if tuple(on) in DIGITS_LOOKUP.keys():\n",
    "            digit = DIGITS_LOOKUP[tuple(on)]\n",
    "        else:\n",
    "            digit = '*'\n",
    "        digits.append(digit)\n",
    "        cv2.rectangle(output_img, (x0, y0), (x1, y1), (0, 128, 0), 2)\n",
    "        cv2.putText(output_img, str(digit), (x0 - 10, y0 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 128, 0), 2)\n",
    "\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_digits_line_method(digits_positions, output_img, input_img):\n",
    "    digits = []\n",
    "    for c in digits_positions:\n",
    "        x0, y0 = c[0]\n",
    "        x1, y1 = c[1]\n",
    "        roi = input_img[y0:y1, x0:x1]\n",
    "        h, w = roi.shape\n",
    "        suppose_W = max(1, int(h / H_W_Ratio))\n",
    "\n",
    "        # Eliminate extraneous symbol interference\n",
    "        if x1 - x0 < 25 and cv2.countNonZero(roi) / ((y1 - y0) * (x1 - x0)) < 0.2:\n",
    "            continue\n",
    "\n",
    "        # Separately identify the case of 1\n",
    "        if w < suppose_W / 2:\n",
    "            x0 = max(x0 + w - suppose_W, 0)\n",
    "            roi = input_img[y0:y1, x0:x1]\n",
    "            w = roi.shape[1]\n",
    "\n",
    "        center_y = h // 2\n",
    "        quater_y_1 = h // 4\n",
    "        quater_y_3 = quater_y_1 * 3\n",
    "        center_x = w // 2\n",
    "        line_width = 5  # line's width\n",
    "        width = (max(int(w * 0.15), 1) + max(int(h * 0.15), 1)) // 2\n",
    "        small_delta = int(h / arc_tan_theta) // 4\n",
    "        segments = [\n",
    "            ((w - 2 * width, quater_y_1 - line_width), (w, quater_y_1 + line_width)),\n",
    "            ((w - 2 * width, quater_y_3 - line_width), (w, quater_y_3 + line_width)),\n",
    "            ((center_x - line_width - small_delta, h - 2 * width), (center_x - small_delta + line_width, h)),\n",
    "            ((0, quater_y_3 - line_width), (2 * width, quater_y_3 + line_width)),\n",
    "            ((0, quater_y_1 - line_width), (2 * width, quater_y_1 + line_width)),\n",
    "            ((center_x - line_width, 0), (center_x + line_width, 2 * width)),\n",
    "            ((center_x - line_width, center_y - line_width), (center_x + line_width, center_y + line_width)),\n",
    "        ]\n",
    "        on = [0] * len(segments)\n",
    "\n",
    "        for (i, ((xa, ya), (xb, yb))) in enumerate(segments):\n",
    "            seg_roi = roi[ya:yb, xa:xb]\n",
    "            # plt.imshow(seg_roi, 'gray')\n",
    "            # plt.show()\n",
    "            total = cv2.countNonZero(seg_roi)\n",
    "            area = (xb - xa) * (yb - ya) * 0.9\n",
    "            # print('prob: ', total / float(area))\n",
    "            if total / float(area) > 0.25:\n",
    "                on[i] = 1\n",
    "        # print('encode: ', on)\n",
    "        if tuple(on) in DIGITS_LOOKUP.keys():\n",
    "            digit = DIGITS_LOOKUP[tuple(on)]\n",
    "        else:\n",
    "            digit = '*'\n",
    "\n",
    "        digits.append(digit)\n",
    "\n",
    "        # Decimal point recognition\n",
    "        # print('dot signal: ',cv2.countNonZero(roi[h - int(3 * width / 4):h, w - int(3 * width / 4):w]) / (9 / 16 * width * width))\n",
    "        if cv2.countNonZero(roi[h - int(3 * width / 4):h, w - int(3 * width / 4):w]) / (9. / 16 * width * width) > 0.65:\n",
    "            digits.append('.')\n",
    "            cv2.rectangle(output_img,\n",
    "                          (x0 + w - int(3 * width / 4), y0 + h - int(3 * width / 4)),\n",
    "                          (x1, y1), (0, 128, 0), 2)\n",
    "            cv2.putText(output_img, 'dot',\n",
    "                        (x0 + w - int(3 * width / 4), y0 + h - int(3 * width / 4) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 128, 0), 2)\n",
    "\n",
    "        cv2.rectangle(output_img, (x0, y0), (x1, y1), (0, 128, 0), 2)\n",
    "        cv2.putText(output_img, str(digit), (x0 + 3, y0 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 128, 0), 2)\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     args = parser.parse_args()\n",
    "#     blurred, gray_img = load_image(args.image_path, show=args.show_image)\n",
    "#     output = blurred\n",
    "#     dst = preprocess(blurred, THRESHOLD, show=args.show_image)\n",
    "#     digits_positions = find_digits_positions(dst)\n",
    "#     digits = recognize_digits_line_method(digits_positions, output, dst)\n",
    "#     if args.show_image:\n",
    "#         cv2.imshow('output', output)\n",
    "#         cv2.waitKey()\n",
    "#         cv2.destroyAllWindows()\n",
    "#     print(digits)\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 2, '*', 5]\n"
     ]
    }
   ],
   "source": [
    "image_path = 'F:/WORK/2023/PULA/OCR/images/pula14.bmp'\n",
    "blurred, gray_img = load_image(image_path, show=False)\n",
    "output = blurred\n",
    "dst = preprocess(blurred, THRESHOLD, show=False)\n",
    "digits_positions = find_digits_positions(dst)\n",
    "digits = recognize_digits_line_method(digits_positions, output, dst)\n",
    "\n",
    "cv2.imshow('output', output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "# if True:\n",
    "#     cv2.imshow('output', output)\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()\n",
    "print(digits)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "606666d8bea24645df8a755f8fcbbbce03fc92d5212136517fec1a8994cd86b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
